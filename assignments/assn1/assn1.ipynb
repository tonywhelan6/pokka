{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonywhelan6/pokka/blob/master/assignments/assn1/assn1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_syyiwYlIzG"
      },
      "source": [
        "## Introductory Machine Learning: Assignment 1\n",
        "\n",
        "**Deadline:**\n",
        "\n",
        "Assignment 1 is due Thursday, February 5 at 11:59 pm. Late work will not be accepted as per the course policies (see the syllabus on Canvas).\n",
        "\n",
        "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. Acknowledge any use of an AI system such as ChatGPT or Copilot.\n",
        "\n",
        "**Submission**\n",
        "\n",
        "Submit your assignment as a pdf file on Gradescope. You can access Gradescope through Canvas on the left-side of the class home page. The problems in each homework assignment are numbered. Note: When submitting on Gradescope, please select the correct pages of your pdf that correspond to each problem. This will allow graders to more easily find your complete solution to each problem.\n",
        "\n",
        "To produce the .pdf, please convert to html and then print to pdf. (You may want to use your pdf print menu to scale the pages to be sure that cells are not truncated.) To convert to html, you can use this [converter notebook](https://colab.research.google.com/github/YData123/sds265-sp26/blob/main/assignments/Convert_ipynb_to_HTML_in_Colab.ipynb).\n",
        "\n",
        "You should start early so that you have time to get help if you're stuck. The drop-in office hours schedule can be found on Canvas. You can also post questions or start discussions on Ed Discussion. The assignment may look long at first glance, but the problems are broken up into steps that should help you to make steady progress.\n",
        "\n",
        "**Topics**\n",
        "\n",
        "1. Linear regression (parametric)\n",
        "2. k-nearest-neighbor classification (nonparametric)\n",
        "\n",
        "This assignment will also help you to learn the essentials of Python, Pandas, and Jupyter notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5STs6B5lIzI"
      },
      "source": [
        "## Problem 1: Linear Regression with Medical Insurance Data (40 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yruU3ybjlIzI"
      },
      "source": [
        "The Medical Insurance dataset is\n",
        "a collection of medical insurance charges and related indicators for individuals.\n",
        "The residential area of the beneficiaries in the US is divided into northeast, southeast, southwest, and northwest.\n",
        "\n",
        "We begin by importing the standard packages in the usual way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54laHD0xlIzI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vWe3EaDlIzJ"
      },
      "source": [
        "### Load the data\n",
        "\n",
        "First, read the whole dataset including individual information, health conditions, and insurance charges for all residential areas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CzvifbdlIzJ"
      },
      "outputs": [],
      "source": [
        "insurance_table = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance_table.tail(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0jP7tuklIzJ"
      },
      "source": [
        "### Explore the dataset\n",
        "\n",
        "We can summarize the key features of the numerical and categorical variables to get a general understanding of the dataset, using exploratory data analysis before fitting any models. For example, we can calculate the correlation matrix among numerical variables, and visualize the distribution of charges stratified by categorical variables using boxplots, violin plots, etc. (Just run the cells below)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8iMn898lIzJ"
      },
      "outputs": [],
      "source": [
        "# this describes the distribution for numeric variables\n",
        "display(insurance_table.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agsiQQXwr0Zl"
      },
      "outputs": [],
      "source": [
        "# this describes categorical variables\n",
        "display(insurance_table.describe(include=['object']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F570b7IMy8_Y"
      },
      "outputs": [],
      "source": [
        "# this displays correlation between numeric variables\n",
        "insurance_table.corr(numeric_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1gX_f8j2Xd0"
      },
      "outputs": [],
      "source": [
        "# plot the histogram for bmi distribution\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.hist(insurance_table[\"bmi\"], bins=30, edgecolor='k')\n",
        "plt.title('BMI Distribution')\n",
        "plt.xlabel('BMI')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r95ONq6x27P3"
      },
      "outputs": [],
      "source": [
        "# boxplot stratified by two categorical variables\n",
        "plt.figure(figsize=(8, 4))\n",
        "smoker_sex_groups = [insurance_table[(insurance_table['smoker'] == 'yes') & (insurance_table['sex'] == 'male')]['charges'],\n",
        "                     insurance_table[(insurance_table['smoker'] == 'yes') & (insurance_table['sex'] == 'female')]['charges'],\n",
        "                     insurance_table[(insurance_table['smoker'] == 'no') & (insurance_table['sex'] == 'male')]['charges'],\n",
        "                     insurance_table[(insurance_table['smoker'] == 'no') & (insurance_table['sex'] == 'female')]['charges']]\n",
        "box_labels = ['Male Smoker', 'Female Smoker', 'Male Non-Smoker', 'Female Non-Smoker']\n",
        "\n",
        "plt.boxplot(smoker_sex_groups, labels=box_labels, patch_artist=True, boxprops={'facecolor': 'lightblue'})\n",
        "plt.title('Charges vs. Smoker (Split by Sex)')\n",
        "plt.xlabel('Category')\n",
        "plt.ylabel('Charges')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AxTbeEElIzJ"
      },
      "source": [
        "### Problem 1.1 (10 Points)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMnlAhq-xFuM"
      },
      "source": [
        "Let's convert the smoker variable to a dummy variable for simplicity. If smoker == yes, encode as 1; otherwise, 0.  \n",
        "\n",
        "In Problem 1.1, we will examine the smoker group, and in Problem 1.2, we will examine the non-smoker group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCxUMrCJxUL8"
      },
      "outputs": [],
      "source": [
        "# convert smoker to dummy variable (just run this cell)\n",
        "insurance_table['smoker'] = pd.Series(np.where(insurance_table.smoker == 'yes',\n",
        "                                               1, 0), insurance_table.index)\n",
        "insurance_table.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Niy5IPhwlIzK"
      },
      "source": [
        "#### Problem 1.1.a\n",
        "\n",
        "Construct a scatter plot to visualize the charges vs. smoker's bmi. Start from splitting the whole insurance data into sub-datasets based on the smoker variable. The x-axis should be `bmi` and y-axis should be `charges` for the **smokers**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4feZ5VDlIzK"
      },
      "outputs": [],
      "source": [
        "smokers = insurance_table[insurance_table['smoker'] == 1]\n",
        "non_smokers = insurance_table[insurance_table['smoker'] == 0]\n",
        "plt.scatter(smokers['bmi'], smokers['charges'])\n",
        "plt.xlabel('BMI')\n",
        "plt.ylabel('Charges')\n",
        "plt.title('Charges vs. BMI for Smokers')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsNxA9oblIzK"
      },
      "source": [
        "#### Problem 1.1.b\n",
        "\n",
        "Now, still based on the smoker sub-dataset, calculate the least-squares estimates of the coefficients for the linear model that includes a slope and an intercept:\n",
        "\n",
        "$$\\text{charges}_i = \\beta_0 + \\beta_1 \\text{bmi}_i + \\epsilon_i$$\n",
        "\n",
        "You may either compute these values with explicit expressions, or use a package such as <code>statsmodels.api.OLS</code>. Use our demo from class as an example, if you wish.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dimFTSoZGFHj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRkG4Bo4lIzK"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "x = smokers['bmi']\n",
        "X = sm.add_constant(x)\n",
        "y = smokers['charges']\n",
        "\n",
        "model = sm.OLS(y, X)\n",
        "results = model.fit()\n",
        "\n",
        "beta0 = results.params['const']\n",
        "beta1 = results.params['bmi']\n",
        "\n",
        "print(f\"beta0 = {beta0}\")\n",
        "print(f\"beta1 = {beta1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni3Nu-4IlIzK"
      },
      "source": [
        "#### Problem 1.1.c\n",
        "\n",
        "Now, plot the data together with the linear fit, shown as a straight line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXWSKGQOlIzK"
      },
      "outputs": [],
      "source": [
        "plt.scatter(smokers['bmi'], smokers['charges'], label = 'Data')\n",
        "x_vals = np.linspace(smokers['bmi'].min(), smokers['bmi'].max(), 100)\n",
        "y_vals = beta0 + beta1 * x_vals\n",
        "\n",
        "plt.xlabel('BMI')\n",
        "plt.ylabel('Charges')\n",
        "plt.title('Charges vs. BMI for Smokers with Linear Fit')\n",
        "plt.plot(x_vals, y_vals, color = 'red')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQTw44TMlIzK"
      },
      "source": [
        "### Problem 1.2 (10 Points)\n",
        "\n",
        "Modify the code in 1.1 to fit and visualize a linear regression model for `charges` vs. `bmi` for the **non-smokers**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P25MSgy3lIzK"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIr00ljAlIzK"
      },
      "source": [
        "#### Problem 1.2.a\n",
        "\n",
        "Visualize the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tj3HewUHlIzK"
      },
      "outputs": [],
      "source": [
        "plt.scatter(non_smokers['bmi'], non_smokers['charges'])\n",
        "plt.xlabel('BMI')\n",
        "plt.ylabel('Charges')\n",
        "plt.title('Charges vs. BMI for Non-Smokers')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLykERKnlIzK"
      },
      "source": [
        "#### Problem 1.2.b\n",
        "\n",
        "Compute a linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrJEjUuflIzK"
      },
      "outputs": [],
      "source": [
        "\n",
        "x = non_smokers['bmi']\n",
        "X = sm.add_constant(x)\n",
        "y = non_smokers['charges']\n",
        "\n",
        "model = sm.OLS(y, X)\n",
        "results = model.fit()\n",
        "\n",
        "beta0 = results.params['const']\n",
        "beta1 = results.params['bmi']\n",
        "\n",
        "print(f\"beta0 = {beta0}\")\n",
        "print(f\"beta1 = {beta1}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EySJAU3lIzK"
      },
      "source": [
        "#### Problem 1.2.c\n",
        "\n",
        "Plot the data together with the linear regression here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOqJClh4lIzK"
      },
      "outputs": [],
      "source": [
        "plt.scatter(non_smokers['bmi'], non_smokers['charges'], label = 'Data')\n",
        "x_vals = np.linspace(smokers['bmi'].min(), non_smokers['bmi'].max(), 100)\n",
        "y_vals = beta0 + beta1 * x_vals\n",
        "\n",
        "plt.xlabel('BMI')\n",
        "plt.ylabel('Charges')\n",
        "plt.title('Charges vs. BMI for Non-Smokers with Linear Fit')\n",
        "plt.plot(x_vals, y_vals, color = 'red')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4XO7AG6lIzK"
      },
      "source": [
        "### Problem 1.3 (5 Points)\n",
        "\n",
        "Compare the linear regression results for 1.1 and 1.2. In which case does the model better fit the data? Please justify your answer *quantitatively*.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The linear regression fits the smoker data better than the non-smoker data. The estimated slope for smokers (B1 = 1473) is ~ 18 times larger than for non smokers (B1 = 83), indicating a substantially stronger relationship between BMI and charges. The plots show the smoker observations lie much closer to the fitted line than the non-smoker data, which exhibits large dispersion and a weak linear trend."
      ],
      "metadata": {
        "id": "bOlGroJEQ_kE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTLer4ublIzL"
      },
      "source": [
        "### Problem 1.4 (15 Points)\n",
        "\n",
        "Now, let's conduct *multiple regression* with two models. The **first** model should be regressing the\n",
        "charges onto bmi and age. And the **second** model onto bmi, age, and smoker. Thus, each of your regressions should have three/four parameters: an intercept, a coefficient for bmi, a coefficient for age, and a coefficient for smoker or not. Explore the difference between adding the smoker variable versus not adding, and describe your observations.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbld-BMKlIzL"
      },
      "outputs": [],
      "source": [
        "X1 = insurance_table[['bmi', 'age']]\n",
        "X1 = sm.add_constant(X1)\n",
        "y = insurance_table['charges']\n",
        "\n",
        "results1 = sm.OLS(y, X1).fit()\n",
        "print(results1.summary())\n",
        "\n",
        "\n",
        "X2 = insurance_table[['bmi', 'age', 'smoker']]\n",
        "X2 = sm.add_constant(X2)\n",
        "\n",
        "results2 = sm.OLS(y, X2).fit()\n",
        "print(results2.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just 11.7 % of the variation in insurance charges can be explained by BMI and age alone, while 74.7 % is explained by BMI, age, and smoking status, indicating that the smoking indicator dramatially improves the model's fit. The estimated smoker coefficient is large and positive, implying a substantial increase in expected charges for smokers. I also noted that the inclusion of the smoker variable also reduced the standard error indicating more precise estimation.\n"
      ],
      "metadata": {
        "id": "6MInTBD_-6PO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRNLrvd1lIzL"
      },
      "source": [
        "## Problem 2: Romance vs. Action (60 Points)\n",
        "\n",
        "Credit: Data 8\n",
        "\n",
        "### Part 1. Exploring the dataset (10 Points)\n",
        "\n",
        "In this problem, we will try to predict\n",
        "a movie's genre from the text of its screenplay. We have compiled a list of 5,000 words that occur in conversations between movie characters. For each movie, our dataset tells us the frequency with which each of these words occurs in certain conversations in its screenplay. All words have been converted to lowercase.\n",
        "\n",
        "Run the cell below to read the `movies` table. It may take up a minute or so to load."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04CX7Hf7lIzL"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import dateutil\n",
        "import random\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unyQzx0BlIzL"
      },
      "outputs": [],
      "source": [
        "movies = pd.read_csv('https://github.com/YData123/sds265-sp26/raw/main/assignments/assn1/movies.csv')\n",
        "movies.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toSb5eH1lIzL"
      },
      "outputs": [],
      "source": [
        "movies.iloc[123,[0, 1, 2, 3, 4, 5, 10, 30, 5005]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n638HirUlIzL"
      },
      "source": [
        "The above cell prints a few columns of the row for the action movie *The Matrix*.  The movie contains 3792 words. The word \"it\" appears 115 times, as it makes up a fraction $\\frac{115}{3792} \\approx 0.030327$ of the words in the movie. The word \"not\" appears 33 times, as it makes up a fraction $\\frac{33}{3792} \\approx 0.00870253$ of the words. The word \"fling\" doesn't appear at all.\n",
        "\n",
        "This numerical representation of a body of text, one that describes only the frequencies of individual words, is called a bag-of-words representation. A lot of information is discarded in this representation: the order of the words, the context of each word, who said what, the cast of characters and actors, etc. However, a bag-of-words representation is often used for machine learning applications as a reasonable starting point, because a great deal of information is also retained and expressed in a convenient and compact format. We will investigate whether this representation is sufficient to build an accurate genre classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Td--m3MlIzL"
      },
      "source": [
        "All movie titles are unique. The `row_for_title` function provides fast access to the one row for each title."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUwjGQpjFAdC"
      },
      "outputs": [],
      "source": [
        "np.linspace(1,1001,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x77qUHSzlIzL"
      },
      "outputs": [],
      "source": [
        "def row_for_title(title):\n",
        "    \"\"\"Return the row for a title\n",
        "\n",
        "    \"\"\"\n",
        "    return movies[movies[\"Title\"]==title]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03lgWQ8KlIzL"
      },
      "source": [
        "For example, the fastest way to find the frequency of \"hey\" in the movie *The Terminator* is to access the `'hey'` item from its row. Check the original table to see if this worked for you!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUJbUE2klIzL"
      },
      "outputs": [],
      "source": [
        "row_for_title('the terminator')[\"hey\"].item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaeahdO5lIzM"
      },
      "source": [
        "This dataset was extracted from [a dataset from Cornell University](http://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html). After transforming the dataset (e.g., converting the words to lowercase, removing profanity, and converting the counts to frequencies), this new dataset was created containing the frequency of 5000 common words in each movie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VppNRtelIzM"
      },
      "outputs": [],
      "source": [
        "print('Words with frequencies:', len(movies.drop(movies.columns[np.arange(6)],axis=1).columns))\n",
        "print('Movies with genres:', len(movies))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bFAiOHylIzM"
      },
      "source": [
        "**Word Stemming**\n",
        "\n",
        "The columns other than \"Title\", \"Genre\", \"Year\", \"Rating\", \"# Votes\" and \"# Words\" in the `movies` table are all words that appear in some of the movies in our dataset.  These words have been *stemmed*, or abbreviated heuristically, in an attempt to make different [inflected](https://en.wikipedia.org/wiki/Inflection) forms of the same base word into the same string.  For example, the column \"manag\" is the sum of proportions of the words \"manage\", \"manager\", \"managed\", and \"managerial\" (and perhaps others) in each movie. This is a common technique used in machine learning and natural language processing.\n",
        "\n",
        "Stemming makes it a little tricky to search for the words you want to use, so we have provided another table that will let you see examples of unstemmed versions of each stemmed word.  Run the code below to load it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2wlhrnflIzM"
      },
      "outputs": [],
      "source": [
        "# Just run this cell.\n",
        "vocab_mapping = pd.read_csv('https://github.com/YData123/sds265-sp26/raw/main/assignments/assn1/stem.csv')\n",
        "stemmed = list(movies.drop(movies.columns[np.arange(6)],axis=1).columns)\n",
        "vocab_table = vocab_mapping[vocab_mapping[\"Stem\"].isin(stemmed)]\n",
        "vocab_table = vocab_table.sort_values('Stem')\n",
        "vocab_table.iloc[np.arange(2000, 2010)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_4WoXITlIzM"
      },
      "source": [
        "### Problem 2.1.a:\n",
        "\n",
        "Assign `stemmed_alternating` to the stemmed version of the word \"alternating\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvJcE_qzlIzM"
      },
      "outputs": [],
      "source": [
        "stemmed_alternating = vocab_table.loc[vocab_table['Word'] == 'alternating', 'Stem'].iloc[0]\n",
        "stemmed_alternating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYzwuMcalIzM"
      },
      "source": [
        "### Problem 2.1.b:\n",
        "\n",
        "Assign `unstemmed_run` to an array of words in `vocab_table` that have \"run\" as its stemmed form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XC-XLLBHlIzM"
      },
      "outputs": [],
      "source": [
        "# Set unstemmed_run to the unstemmed versions of \"run\" (which\n",
        "# should be an array of string).\n",
        "unstemmed_run = vocab_table.loc[vocab_table[\"Stem\"] == \"run\", \"Word\"].values\n",
        "unstemmed_run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOanoBg9lIzM"
      },
      "source": [
        "**Splitting the dataset**\n",
        "\n",
        "We're going to use our `movies` dataset for two purposes.\n",
        "\n",
        "1. First, we want to *train* a movie genre classifier.\n",
        "2. Second, we want to *test* the performance of the classifier.\n",
        "\n",
        "So, we need two different datasets: *training* and *test*.\n",
        "\n",
        "The purpose of a classifier is to classify unseen data that is similar to the training data. Therefore, we must ensure that there are no movies that appear in both sets. We do so by splitting the dataset randomly. The dataset has already been permuted randomly, so it's easy to split.  We just take the top for training and the rest for test.\n",
        "\n",
        "Run the code below (without changing it) to separate the datasets into two tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVWZ9VrwlIzM"
      },
      "outputs": [],
      "source": [
        "# Here we have defined the proportion of our data\n",
        "# that we want to designate for training as 17/20ths\n",
        "# of our total dataset.  3/20ths of the data is\n",
        "# reserved for testing.\n",
        "\n",
        "training_proportion = 17/20\n",
        "\n",
        "num_movies = len(movies)\n",
        "num_train = int(num_movies * training_proportion)\n",
        "num_test = num_movies - num_train\n",
        "\n",
        "train_movies = movies.iloc[np.arange(num_train)]\n",
        "test_movies = movies.iloc[np.arange(num_train, num_movies)]\n",
        "\n",
        "print(\"Training: \",   len(train_movies), \";\",\n",
        "      \"Test: \",       len(test_movies))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NMBNP2WlIzM"
      },
      "source": [
        "### Problem 2.1.c:\n",
        "\n",
        "Draw a horizontal bar chart with two bars that show the proportion of Action movies in each dataset.  Complete the function `action_proportion` first; it should help you create the bar chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEM4NxdRlIzM"
      },
      "outputs": [],
      "source": [
        "def action_proportion(dataframe):\n",
        "    \"\"\"Return the proportion of movies in a table that have the Action genre.\"\"\"\n",
        "    return dataframe[\"action\"].mean()\n",
        "\n",
        "train_action = action_proportion(train_movies)\n",
        "test_action = action_proportion(test_movies)\n",
        "\n",
        "plt.barh([\"Training\", \"Test\"], [train_action, test_action])\n",
        "plt.xlabel(\"Proportion of Action Movies\")\n",
        "plt.title(\"Proportion of Action Movies in Training and Test Sets\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwsyKG5AlIzN"
      },
      "source": [
        "### Part 2. K-Nearest Neighbors: A guided example (20 Points)\n",
        "\n",
        "k-Nearest Neighbors (k-NN) is a classification algorithm.  Given some *attributes* (also called *features*) of an unseen example, it decides whether that example belongs to one or the other of two categories based on its similarity to previously seen examples. Predicting the category of an example is called *labeling*, and the predicted category is also called a *label*.\n",
        "\n",
        "An attribute (feature) we have about each movie is *the proportion of times a particular word appears in the movies*, and the labels are two movie genres: romance and action.  The algorithm requires many previously seen examples for which both the attributes and labels are known: that's the `train_movies` dataframe.\n",
        "\n",
        "To build understanding, we're going to visualize the algorithm instead of just describing it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0fZwoxnlIzN"
      },
      "source": [
        "**Classifying a movie**\n",
        "\n",
        "In k-NN, we classify a movie by finding the `k` movies in the *training set* that are most similar according to the features we choose. We call those movies with similar features the *nearest neighbors*.  The k-NN algorithm assigns the movie to the most common category among its `k` nearest neighbors.\n",
        "\n",
        "Let's limit ourselves to just 2 features for now, so we can plot each movie.  The features we will use are the proportions of the words \"money\" and \"feel\" in the movie.  Taking the movie \"Batman Returns\" (in the test set), 0.000502 of its words are \"money\" and 0.004016 are \"feel\". This movie appears in the test set, so let's imagine that we don't yet know its genre.\n",
        "\n",
        "First, we need to make our notion of similarity more precise.  We will say that the *distance* between two movies is the straight-line distance between them when we plot their features in a scatter diagram. This distance is called the Euclidean (\"yoo-KLID-ee-un\") distance, whose formula is $\\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}$.\n",
        "\n",
        "For example, in the movie *Titanic* (in the training set), 0.0009768 of all the words in the movie are \"money\" and 0.0017094 are \"feel\".  Its distance from *Batman Returns* on this 2-word feature set is $$\\sqrt{(0.000502 - 0.0009768)^2 + (0.004016 - 0.0017094)^2} \\approx 0.00235496.$$  (If we included more or different features, the distance could be different.)\n",
        "\n",
        "A third movie, *The Avengers* (in the training set), is 0 \"money\" and 0.001115 \"feel\".\n",
        "\n",
        "The function below creates a plot to display the \"money\" and \"feel\" features of a test movie and some training movies. As you can see in the result, *Batman Returns* is more similar to *Titanic* than to *The Avengers* based on these features. However, we know that *Batman Returns* and *The Avengers* are both action movies, so intuitively we'd expect them to be more similar. Unfortunately, that isn't always the case. We'll discuss this more later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jA2Pp_AzlIzN"
      },
      "outputs": [],
      "source": [
        "# Just run this cell.\n",
        "def plot_embeddings(M_reduced, word2Ind, words):\n",
        "    \"\"\"\n",
        "        Plot in a scatterplot the embeddings of the words specified in the list \"words\".\n",
        "        Include a label next to each point.\n",
        "    \"\"\"\n",
        "    for word in words:\n",
        "        x, y = M_reduced[word2Ind[word]]\n",
        "        plt.scatter(x, y, marker='x', color='red')\n",
        "        plt.text(x+.03, y+.03, word, fontsize=9)\n",
        "    plt.show()\n",
        "\n",
        "M_reduced_plot_test = np.array([[1, 1], [-1, -1], [1, -1], [-1, 1], [0, 0]])\n",
        "word2Ind_plot_test = {'test1': 0, 'test2': 1, 'test3': 2, 'test4': 3, 'test5': 4}\n",
        "words = ['test1', 'test2', 'test3', 'test4', 'test5']\n",
        "plot_embeddings(M_reduced_plot_test, word2Ind_plot_test, words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93txZVUXlIzN"
      },
      "outputs": [],
      "source": [
        "# Just run this cell.\n",
        "def plot_with_two_features(test_movie, training_movies, x_feature, y_feature):\n",
        "    \"\"\"Plot a test movie and training movies using two features.\"\"\"\n",
        "    test_row = row_for_title(test_movie)\n",
        "    test_x = test_row[x_feature].item()\n",
        "    test_y = test_row[y_feature].item()\n",
        "    plt.scatter(test_x, test_y, s=100)\n",
        "    plt.text(test_x, test_y+.0005, test_movie, fontsize=20)\n",
        "    for movie in training_movies:\n",
        "        row = row_for_title(movie)\n",
        "        train_x = row[x_feature].item()\n",
        "        train_y = row[y_feature].item()\n",
        "        plt.scatter(train_x, train_y, s=100)\n",
        "        plt.text(train_x, train_y+.0005, movie, fontsize=20)\n",
        "    plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.xlim(-0.0005, 0.002)\n",
        "plt.ylim(-0.001, 0.006)\n",
        "plt.xlabel('money', fontsize=25)\n",
        "plt.ylabel('feel', fontsize=25)\n",
        "\n",
        "training = [\"titanic\", \"the avengers\"]\n",
        "plot_with_two_features(\"batman returns\", training, \"money\", \"feel\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bonPB9wlIzN"
      },
      "source": [
        "### Problem 2.2.a:\n",
        "\n",
        "Compute the distance between the two action movies, *Batman Returns* and *The Avengers*, using the `money` and `feel` features only.  Assign it the name `action_distance`.\n",
        "\n",
        "**Note:** If you have a row, you can use `item` to get a value from a column by its name.  For example, if `r` is a row, then `r[\"Genre\"].item()` is the value in column `\"Genre\"` in row `r`.\n",
        "\n",
        "*Hint*: Remember the function `row_for_title`, redefined for you below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgkaW7BQlIzN"
      },
      "outputs": [],
      "source": [
        "def row_for_title(title):\n",
        "    \"\"\"Return the row for a title\n",
        "\n",
        "    \"\"\"\n",
        "    return movies[movies[\"Title\"]==title]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3Y7oSvblIzN"
      },
      "outputs": [],
      "source": [
        "batman = row_for_title(\"batman returns\")\n",
        "avengers = row_for_title(\"the avengers\")\n",
        "action_distance = ...\n",
        "action_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ullWxlKlIzN"
      },
      "source": [
        "Below, we've added a third training movie, *The Terminator*. Before, the point closest to *Batman Returns* was *Titanic*, a romance movie. However, now the closest point is *The Terminator*, an action movie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wPCWPEMlIzN"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "plt.xlim(-0.0005, 0.002)\n",
        "plt.ylim(-0.001, 0.006)\n",
        "plt.xlabel('money', fontsize=25)\n",
        "plt.ylabel('feel', fontsize=25)\n",
        "\n",
        "training = [\"the avengers\", \"titanic\", \"the terminator\"]\n",
        "plot_with_two_features(\"batman returns\", training, \"money\", \"feel\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xImxXk0AlIzN"
      },
      "source": [
        "### Problem 2.2.b:\n",
        "\n",
        "Complete the function `distance_two_features` that computes the Euclidean distance between any two movies, using two features. The last two lines call your function to show that *Batman Returns* is closer to *The Terminator* than *The Avengers*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0omuArZlIzN"
      },
      "outputs": [],
      "source": [
        "def distance_two_features(title0, title1, x_feature, y_feature):\n",
        "    \"\"\"Compute the distance between two movies with titles title0 and title1\n",
        "\n",
        "    Only the features named x_feature and y_feature are used when computing the distance.\n",
        "    \"\"\"\n",
        "    row0 = ...\n",
        "    row1 = ...\n",
        "    ...\n",
        "\n",
        "for movie in [\"the terminator\", \"the avengers\"]:\n",
        "    movie_distance = distance_two_features(movie, \"batman returns\", \"money\", \"feel\")\n",
        "    print(movie, 'distance:\\t', movie_distance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S6P3Cy2lIzN"
      },
      "source": [
        "### Problem 2.2.c:\n",
        "\n",
        "Define the function `distance_from_batman_returns` so that it works as described in its documentation.\n",
        "\n",
        "**Note:** Your solution should not use arithmetic operations directly. Instead, it should make use of existing functionality above!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKDq1AhKlIzN"
      },
      "outputs": [],
      "source": [
        "def distance_from_batman_returns(title):\n",
        "    \"\"\"The distance between the given movie and \"batman returns\", based on the features \"money\" and \"feel\".\n",
        "\n",
        "    This function takes a single argument:\n",
        "      title: A string, the name of a movie.\n",
        "    \"\"\"\n",
        "\n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbRXlalNlIzO"
      },
      "source": [
        "### Problem 2.2.d:\n",
        "\n",
        "Using the features `\"money\"` and `\"feel\"`, what are the names and genres of the 7 movies in the **training set** closest to \"batman returns\"?  To answer this question, make a table named `close_movies` containing those 7 movies with columns `\"Title\"`, `\"Genre\"`, `\"money\"`, and `\"feel\"`, as well as a column called `\"distance from batman\"` that contains the distance from \"batman returns\".  The dataframe should be **sorted in ascending order by `distance from batman`**.\n",
        "\n",
        "*Hint*: You may find the function [`insert`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.insert.html) useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pk-oK70VlIzO"
      },
      "outputs": [],
      "source": [
        "# The sample solution took multiple lines.\n",
        "...\n",
        "close_movies = ...\n",
        "close_movies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_PYakxalIzO"
      },
      "source": [
        "### Problem 2.2.e:\n",
        "\n",
        "Next, we'll classify \"batman returns\" based on the genres of the closest movies.\n",
        "\n",
        "To do so, define the function `most_common` so that it works as described in its documentation below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7dM1ZlHlIzO"
      },
      "outputs": [],
      "source": [
        "def most_common(label, dataframe):\n",
        "    \"\"\"The most common element in a column of a table.\n",
        "\n",
        "    This function takes two arguments:\n",
        "      label: The label of a column, a string.\n",
        "      dataframe: A dataframe.\n",
        "\n",
        "    It returns the most common value in that column of that table.\n",
        "    In case of a tie, it returns any one of the most common values\n",
        "    \"\"\"\n",
        "    ...\n",
        "\n",
        "# Calling most_common on your table of 7 nearest neighbors classifies\n",
        "# \"batman returns\" as a romance movie, 5 votes to 2.\n",
        "most_common('Genre', close_movies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJMYOX05lIzO"
      },
      "source": [
        "Congratulations, you've classified your first movie! However, we can see that the classifier doesn't work too well since it categorized *Batman Returns* as a romance movie. Let's see if we can do better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4tdMh3IlIzO"
      },
      "source": [
        "### Part 3. Features (20 Points)\n",
        "\n",
        "Now, we're going to extend our classifier to consider more than two features at a time.\n",
        "\n",
        "Euclidean distance still makes sense with more than two features. For `n` different features, we compute the difference between corresponding feature values for two movies, square each of the `n`  differences, sum up the resulting numbers, and take the square root of the sum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwUyG2rylIzO"
      },
      "source": [
        "### Problem 2.3.a:\n",
        "\n",
        "Write a function to compute the Euclidean distance between two **arrays** of features of *arbitrary* (but equal) length.  Use it to compute the distance between the first movie in the training set and the first movie in the test set, *using all of the features*.  (Remember that the first six columns of your tables are not features.)\n",
        "\n",
        "**Note:** To convert rows to arrays, use `np.array`. For example, if `df` was a dataframe, `np.array(df.iloc[i])` converts row i of `df` into an array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VPEPPL_lIzO"
      },
      "outputs": [],
      "source": [
        "def distance(features1, features2):\n",
        "    \"\"\"The Euclidean distance between two arrays of feature values.\"\"\"\n",
        "    ...\n",
        "\n",
        "distance_first_to_first = ...\n",
        "distance_first_to_first"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHBxTcqblIzO"
      },
      "source": [
        "**Creating your own feature set**\n",
        "\n",
        "Unfortunately, using all of the features has some downsides.  One clear downside is *computational* -- computing Euclidean distances just takes a long time when we have lots of features.  You might have noticed that in the last question!\n",
        "\n",
        "So we're going to select just 20.  We'd like to choose features that are very *discriminative*. That is, features which lead us to correctly classify as much of the test set as possible.  This process of choosing features that will make a classifier work well is sometimes called *feature selection*, or more broadly *feature engineering*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtJSBnU1lIzO"
      },
      "source": [
        "### Problem 2.3.b:\n",
        "\n",
        "In this question, we will help you get started on selecting more effective features for distinguishing romance from action movies. The plot below (generated for you) shows the average number of times each word occurs in a romance movie on the horizontal axis and the average number of times it occurs in an action movie on the vertical axis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e1_GCWUlIzO"
      },
      "source": [
        "![alt text](https://github.com/YData123/sds265-sp26/raw/main/assignments/assn1/word_plot.png \"Title\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWnJ6f8tlIzO"
      },
      "source": [
        "### Problem 2.3.c:\n",
        "\n",
        "Using the plot above, choose 20 common words that you think might let you distinguish between romance and action movies. Make sure to choose words that are frequent enough that every movie contains at least one of them. Don't just choose the 20 most frequent, though... you can do much better.\n",
        "\n",
        "You might want to come back to this question later to improve your list, once you've seen how to evaluate your classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFzDwRkMlIzO"
      },
      "outputs": [],
      "source": [
        "# Set my_20_features to a list of 20 features (strings that are column labels)\n",
        "\n",
        "my_20_features = []\n",
        "\n",
        "train_20 = train_movies[my_20_features]\n",
        "test_20 = test_movies[my_20_features]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0ntmcm2lIzO"
      },
      "source": [
        "In two sentences or less, describe how you selected your features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaONyX6GlIzO"
      },
      "source": [
        "*Write your answer here, replacing this text.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rIiT-iClIzO"
      },
      "source": [
        "Next, let's classify the first movie from our test set using these features.  You can examine the movie by running the cells below. Do you think it will be classified correctly?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Txy4WZRKlIzO"
      },
      "outputs": [],
      "source": [
        "print(\"Movie:\")\n",
        "print(test_movies.iloc[0,[0,1]])\n",
        "print(\"Features:\")\n",
        "print(test_20.iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmPEJmbDlIzP"
      },
      "source": [
        "As before, we want to look for the movies in the training set that are most like our test movie.  We will calculate the Euclidean distances from the test movie (using the 20 selected features) to all movies in the training set.  You could do this with a `for` loop, but to make it computationally faster, we have provided a function, `fast_distances`, to do this for you.  Read its documentation to make sure you understand what it does.  (You don't need to understand the code in its body unless you want to.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL1wowWslIzP"
      },
      "outputs": [],
      "source": [
        "# Just run this cell to define fast_distances.\n",
        "\n",
        "def fast_distances(test_row, train_dataframe):\n",
        "    \"\"\"An array of the distances between test_row and each row in train_rows.\n",
        "\n",
        "    Takes 2 arguments:\n",
        "      test_row: A row of a table containing features of one\n",
        "        test movie (e.g., test_20.iloc[0]).\n",
        "      train_table: A table of features (for example, the whole\n",
        "        table train_20).\"\"\"\n",
        "    assert len(train_dataframe.columns) < 50, \"Make sure you're not using all the features of the movies table.\"\n",
        "    counts_matrix = np.asmatrix(train_20.values)\n",
        "    diff = np.tile(test_row.values, [counts_matrix.shape[0], 1]) - counts_matrix\n",
        "    np.random.seed(0) # For tie breaking purposes\n",
        "    distances = np.squeeze(np.asarray(np.sqrt(np.square(diff).sum(1))))\n",
        "    eps = np.random.uniform(size=distances.shape)*1e-10 #Noise for tie break\n",
        "    distances = distances + eps\n",
        "    return distances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqLDFj0OlIzP"
      },
      "source": [
        "### Problem 2.3.d:\n",
        "\n",
        "Use the `fast_distances` function provided above to compute the distance from the first movie in the test set to all the movies in the training set, **using your set of 20 features**.  Make a new dataframe called `genre_and_distances` with one row for each movie in the training set and three columns:\n",
        "* The `\"Title\"` of the training movie\n",
        "* The `\"Genre\"` of the training movie\n",
        "* The `\"Distance\"` from the first movie in the test set\n",
        "\n",
        "Ensure that `genre_and_distances` is **sorted in increasing order by distance to the first test movie**.\n",
        "\n",
        "*Hint*: You may find the function [`sort_values`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html) useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SD_6LHOMlIzP"
      },
      "outputs": [],
      "source": [
        "genre_and_distances = ...\n",
        "genre_and_distances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyE1DyWelIzP"
      },
      "source": [
        "### Problem 2.3.e:\n",
        "\n",
        "Now compute the 5-nearest neighbors classification of the first movie in the test set.  That is, decide on its genre by finding the most common genre among its 5 nearest neighbors in the training set, according to the distances you've calculated.  Then check whether your classifier chose the right genre.  (Depending on the features you chose, your classifier might not get this movie right, and that's okay.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG7KTjr0lIzP"
      },
      "outputs": [],
      "source": [
        "# Set my_assigned_genre to the most common genre among these.\n",
        "my_assigned_genre = ...\n",
        "\n",
        "# Set my_assigned_genre_was_correct to True if my_assigned_genre\n",
        "# matches the actual genre of the first movie in the test set.\n",
        "my_assigned_genre_was_correct = ...\n",
        "\n",
        "print(\"The assigned genre, {}, was{}correct.\".format(my_assigned_genre, \" \" if my_assigned_genre_was_correct else \" not \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAHjigB0lIzP"
      },
      "source": [
        "**A classifier function**\n",
        "\n",
        "Now we can write a single function that encapsulates the whole process of classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgSSnyCVlIzP"
      },
      "source": [
        "### Problem 2.3.f:\n",
        "\n",
        "Write a function called `classify`.  It should take the following four arguments:\n",
        "* A row of features for a movie to classify (e.g., `test_20.iloc[0]`).\n",
        "* A table with a column for each feature (e.g., `train_20`).\n",
        "* An array of classes that has as many items as the previous table has rows, and in the same order.\n",
        "* `k`, the number of neighbors to use in classification.\n",
        "\n",
        "It should return the class a `k`-nearest neighbor classifier picks for the given row of features (the string `'Romance'` or the string `'Action'`).\n",
        "\n",
        "*Hint:* You may find [`Counter().most_common()`](https://docs.python.org/3/library/collections.html#collections.Counter) helpful for finding the classification result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4hiOX7YlIzP"
      },
      "outputs": [],
      "source": [
        "def classify(test_row, train_rows, train_labels, k):\n",
        "    \"\"\"Return the most common class among k nearest neighbors to test_row.\"\"\"\n",
        "    distances = fast_distances(test_row, train_rows)\n",
        "    genre_and_distances = ...\n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkYRwd-wlIzP"
      },
      "source": [
        "### Problem 2.3.g:\n",
        "\n",
        "Assign `king_kong_genre` to the genre predicted by your classifier for the movie \"king kong\" in the test set, using **11 neighbors** and using your 20 features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXIvk-1QlIzP"
      },
      "outputs": [],
      "source": [
        "# The sample solution first defined a row called king_kong_features.\n",
        "king_kong_features = ...\n",
        "king_kong_genre = ...\n",
        "king_kong_genre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH3m24fGlIzP"
      },
      "source": [
        "Finally, when we evaluate our classifier, it will be useful to have a classification function that is specialized to use a fixed training set and a fixed value of `k`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDuq0-sflIzP"
      },
      "source": [
        "### Problem 2.3.h:\n",
        "\n",
        "Create a classification function that takes as its argument a row containing your 20 features and classifies that row using the 11-nearest neighbors algorithm with `train_20` as its training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3rfOEmllIzP"
      },
      "outputs": [],
      "source": [
        "def classify_feature_row(row):\n",
        "    ...\n",
        "\n",
        "# When you're done, this should produce 'Romance' or 'Action'.\n",
        "classify_feature_row(test_20.iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F-DCMeklIzP"
      },
      "source": [
        "### Part 4: Evaluating your classifier (10 Points)\n",
        "\n",
        "Now that it's easy to use the classifier, let's see how accurate it is on the whole test set.\n",
        "\n",
        "### Problem 2.4.a:\n",
        "\n",
        "Use `classify_feature_row` and [`pandas.DataFrame.apply`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html) (or a loop) to classify every movie in the test set.  Assign these guesses as an array to `test_guesses`.  **Then**, compute the proportion of correct classifications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V174I8LclIzQ"
      },
      "outputs": [],
      "source": [
        "test_guesses = ...\n",
        "proportion_correct = ...\n",
        "proportion_correct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7nOHGi2lIzQ"
      },
      "source": [
        "### Problem 2.4.b:\n",
        "\n",
        "An important part of evaluating your classifiers is figuring out where they make mistakes. Assign the name `test_movie_correctness` to a dataframe with three columns, `'Title'`, `'Genre'`, and `'Was correct'`. The last column should contain `True` or `False` depending on whether or not the movie was classified correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZ5vt4H-lIzQ"
      },
      "outputs": [],
      "source": [
        "test_movie_correctness = ...\n",
        "#test_movie_correctness.sort_values('Was correct')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpJxfz-plIzQ"
      },
      "source": [
        "### Problem 2.4.c:\n",
        "\n",
        "Do you see a pattern in the mistakes that your classifier makes? In two sentences or less, describe any patterns you see in the results or any other interesting findings from the table above. If you need some help, try looking up the movies that your classifier got wrong on Wikipedia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uATi9fW5lIzQ"
      },
      "source": [
        "*Write your answer here, replacing this text.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR7h0wzClIzQ"
      },
      "source": [
        "At this point, you've gone through one cycle of classifier design.  Let's summarize the steps:\n",
        "1. From available data, select test and training sets.\n",
        "2. Choose an algorithm you're going to use for classification.\n",
        "3. Identify some features.\n",
        "4. Define a classifier function using your features and the training set.\n",
        "5. Evaluate its performance (the proportion of correct classifications) on the test set."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "265-sp26-staff (3.11.14)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}